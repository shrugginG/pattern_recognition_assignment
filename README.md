# 模式识别课程作业
## 姓名：卢俊羲 学号：239288 学院：网络空间安全学院
## 引言

作为最为常见的Web攻击手段之一，钓鱼攻击旨在通过伪造界面窃取受害者的敏感信息。钓鱼网站攻击者通常尝试冒充众所周知并广泛使用的服务，如社交媒体、银行和电子商务网站。这些仿冒网站通常建立在与原始站点相同的代码基础上，这可能使它们在第一眼看来难以被发现。我们可以通过许多相关指标来区分良性和钓鱼网站。例如，大多数钓鱼URL往往非常长，带有多个子域和特殊字符。域名通常托管在可疑的主机上，并使用由不受信任的机构颁发的安全套接层（SSL）证书。目前有许多工作旨在实现针对钓鱼网站攻击的防御。其中一些实现使用传统技术，如黑名单或URL词汇特征分析。然而，黑名单存在多个缺点，如需要人工辅助更新且缺乏全面性。此外，它们不能用于未知和隐藏的URL。其他技术利用机器学习来训练模型，根据一定数量的样本对网站进行分类。然而，在大多数方法中，并未涉及网站的超链接结构。

本次课程作业设计了一个利用超链接结构特征进行网站分类的模型。此外还对模型的表现进行了评估。获得的性能结果证明了的方法在检测精度方面的效率和有效性，以及其在超越现有检测方法方面的能力。

## 方案

### 相关基础
图神经网络

图神经网络（GNNs）是一种以图数据为输入的神经网络类型。与其他神经网络架构不同，GNNs能够处理非欧几里得数据和对象之间的复杂关系。大多数GNNs遵循消息传递模型（MPNN）（Gilmer等，2017年），可以被认为是图的卷积神经网络（CNN）的概括。这种消息传递算法以图G=(V,E)作为输入，其中n个节点vi属于V，m条边(vi,vj)属于E，G可以是有向或无向的。每个节点和边都可以分别存储一个特征向量，称为节点特征和边特征。通常，所有这些信息都通过三个矩阵表示：

A：图结构矩阵，邻接矩阵情况下形状为n×n，对于CSR（压缩稀疏行）或COO（坐标）稀疏矩阵则为2×n。
X：节点特征矩阵，形状为n×d。
E：边特征矩阵，形状为m×e。
其中，n=|V|，m=|E|，d和e分别是每个节点和每条边的特征数量。

消息传递模型由四个步骤组成，其中步骤1到3由一个GNN层实现，并且随着层数的增加多次重复。步骤4是一个最终步骤，应在通过所有GNN层后应用。

消息：每个节点根据其节点特征创建一个消息并发送给所有邻居。
聚合：节点使用聚合函数聚合来自每个邻居的传入消息。
更新：节点的旧特征通过与聚合的新特征合并来更新，创建节点嵌入。
读出：将所有节点嵌入组合成一个表示，可以用于下游机器学习算法进行预测。
每个步骤通常是一个具有可学习参数的函数，即在两个步骤的计算中使用权重矩阵和激活函数。一个GNN层通常对应于特征在1-hop邻域内的传播，所以堆叠n个GNN层将导致节点特征传播到n个远程节点。在这些层中，每个节点收集其邻居的特征，以产生图嵌入。

### 模型介绍
本次作业完成了一个基于图神经网络的网站分类（钓鱼或良性）模型。模型可以被认为是GNN架构的附加层。模型使用图来表述网站的超链接结构。模型将钓鱼网站分类的任务视为一个节点分类任务，其中要分类的节点是给定的URL，其他节点代表从该URL发出的每个可能的链接，直到用户定义的深度。从这些链接中可以构建一个图，其中节点代表URL，边是从`<a>、<form>`或`<iframe>`标签提取的URL之间的链接。更准确地说，图是一个根图，根节点是要分类的网站（命名为根URL）。输入数据集包含一个根URL列表，映射为钓鱼或良性标签。对于提供的数据集中的每个URL，都会提取一个特征向量，以及从该根URL出发的所有URLs（子URLs）的向量。这些子URLs的特征也被提取出来。特征向量用于构建特征矩阵X。子URLs用于构建实际的图结构矩阵A。

模型为半监督模型。已知的标签是实际的根URL，未知的标签代表每个子URL。分类器在数据集中的每个监督样本上进行训练，然后对其他无监督样本进行推理。之后，使用传统的GNN和消息传递将从分类节点收集信息以构建嵌入。

### 模型使用说明
#### 项目结构：

- pattern_recognition_assignment/(项目根目录)
  - data/(数据集目录)
    - train/
      - processed/
  - dataset/(数据集处理)
    - dataprep.py  
    - dataset_v2.py  
    - other_models.py
  - models/(课程作业模型)
    - ffn.py  
    - gcn.py
  - utils/(相关工具)
    - compute_device.py
    - utils.py
  - main.py(运行入口)
#### 项目依赖
```
torch 
PyG
```
### 运行结果
```
  ~/project/PhD_course/pattern_recognition_assignment                                                                          37s  phishGNN_env  0.74  120G  30%  x86_64
jxlu@SEU-HuLab-Machine05 ❯ /home/jxlu/module/miniconda3/envs/phishGNN_env/bin/python /home/jxlu/project/PhD_course/pattern_recognition_assignment/main.py          211.65.197.80
Num GPUs Available: 1
Torch version: 2.1.0
Compute device: cuda
Torch geometric version: 2.4.0
Processing...
Done!
epoch: 0, train_loss:0.25379312405458504, val_loss:0.31925469636917114, test_acc:0.8099352051835853
epoch: 1, train_loss:0.13515344156030698, val_loss:0.2372014969587326, test_acc:0.8412526997840173
epoch: 2, train_loss:0.12902223706414206, val_loss:0.3190252482891083, test_acc:0.838012958963283
epoch: 3, train_loss:0.11644356988480262, val_loss:0.2776387333869934, test_acc:0.8434125269978402
epoch: 4, train_loss:0.11474892919556952, val_loss:0.2120380848646164, test_acc:0.8887688984881209
epoch: 5, train_loss:0.1105745832473629, val_loss:0.2546335756778717, test_acc:0.8671706263498921
epoch: 6, train_loss:0.10367596615608199, val_loss:0.20155124366283417, test_acc:0.8995680345572354
epoch: 7, train_loss:0.10004475026792307, val_loss:0.246547669172287, test_acc:0.8887688984881209
epoch: 8, train_loss:0.10581742568662894, val_loss:0.4300362467765808, test_acc:0.8272138228941684
epoch: 9, train_loss:0.0981277748379764, val_loss:0.2538853585720062, test_acc:0.8801295896328294
epoch: 10, train_loss:0.10049570862140877, val_loss:0.32397642731666565, test_acc:0.8682505399568035
epoch: 11, train_loss:0.09101358726111645, val_loss:0.4268766939640045, test_acc:0.8617710583153347
epoch: 12, train_loss:0.08202281603753749, val_loss:0.37627020478248596, test_acc:0.8758099352051836
epoch: 13, train_loss:0.08961663913706445, val_loss:0.363463819026947, test_acc:0.8606911447084233
epoch: 14, train_loss:0.08785838181610396, val_loss:0.454455703496933, test_acc:0.8639308855291576
epoch: 15, train_loss:0.08628019771154559, val_loss:0.4259824752807617, test_acc:0.8660907127429806
epoch: 16, train_loss:0.08292041497398134, val_loss:0.5431166887283325, test_acc:0.8488120950323974
epoch: 17, train_loss:0.08072677307388136, val_loss:0.40216732025146484, test_acc:0.8725701943844493
epoch: 18, train_loss:0.08219996222764714, val_loss:0.4682154953479767, test_acc:0.8822894168466523
epoch: 19, train_loss:0.07913588486271597, val_loss:0.5183752179145813, test_acc:0.8725701943844493
epoch: 20, train_loss:0.08129100686998107, val_loss:0.5700710415840149, test_acc:0.8736501079913607
epoch: 21, train_loss:0.07833422338526397, val_loss:0.805347204208374, test_acc:0.8552915766738661
epoch: 22, train_loss:0.07686890322944107, val_loss:0.5934685468673706, test_acc:0.8822894168466523
epoch: 23, train_loss:0.0742487517520062, val_loss:0.6457592248916626, test_acc:0.8606911447084233
epoch: 24, train_loss:0.07964968297554194, val_loss:0.5025338530540466, test_acc:0.847732181425486
epoch: 25, train_loss:0.07487675853821066, val_loss:0.451801598072052, test_acc:0.8758099352051836
epoch: 26, train_loss:0.0744360768775724, val_loss:0.46033674478530884, test_acc:0.8768898488120951
epoch: 27, train_loss:0.07356426746178256, val_loss:0.5183137059211731, test_acc:0.8822894168466523
epoch: 28, train_loss:0.06705990757060454, val_loss:0.7051002383232117, test_acc:0.8790496760259179
epoch: 29, train_loss:0.06643467025710112, val_loss:0.6180071234703064, test_acc:0.8585313174946004
epoch: 30, train_loss:0.07081290384160448, val_loss:0.7068288326263428, test_acc:0.8650107991360692
epoch: 31, train_loss:0.07405880424711439, val_loss:0.5501441955566406, test_acc:0.8628509719222462
epoch: 32, train_loss:0.07193166879801088, val_loss:0.7120096683502197, test_acc:0.8542116630669546
epoch: 33, train_loss:0.07235163635366985, val_loss:0.6348916888237, test_acc:0.857451403887689
epoch: 34, train_loss:0.07282413750436828, val_loss:0.6675928831100464, test_acc:0.8617710583153347
epoch: 35, train_loss:0.0635257378268782, val_loss:0.7634062170982361, test_acc:0.8682505399568035
epoch: 36, train_loss:0.06262384747623519, val_loss:0.6699585914611816, test_acc:0.8974082073434125
epoch: 37, train_loss:0.06873978866637288, val_loss:0.7109401226043701, test_acc:0.8779697624190065
epoch: 38, train_loss:0.07725764743693063, val_loss:0.6213796734809875, test_acc:0.8714902807775378
epoch: 39, train_loss:0.07413946240015143, val_loss:0.6815527677536011, test_acc:0.8920086393088553
epoch: 40, train_loss:0.07039358685746205, val_loss:0.6238093972206116, test_acc:0.8801295896328294
epoch: 41, train_loss:0.06893647682016829, val_loss:0.6482158303260803, test_acc:0.8725701943844493
epoch: 42, train_loss:0.0626127036239487, val_loss:0.6083664298057556, test_acc:0.8736501079913607
epoch: 43, train_loss:0.07110041127959116, val_loss:0.8565245270729065, test_acc:0.8714902807775378
epoch: 44, train_loss:0.062081502129048165, val_loss:0.9020164012908936, test_acc:0.8747300215982722
epoch: 45, train_loss:0.06033142478061597, val_loss:0.9206596612930298, test_acc:0.8704103671706264
epoch: 46, train_loss:0.07199829914806366, val_loss:1.1120878458023071, test_acc:0.8315334773218143
epoch: 47, train_loss:0.0661806811878966, val_loss:0.7729018926620483, test_acc:0.8866090712742981
epoch: 48, train_loss:0.06468197657883767, val_loss:0.8236759901046753, test_acc:0.8855291576673866
epoch: 49, train_loss:0.061934686867009175, val_loss:0.913880467414856, test_acc:0.8909287257019438
total_acc: 0.8679049676025917
```
最终平均准确率：0.8679049676025917